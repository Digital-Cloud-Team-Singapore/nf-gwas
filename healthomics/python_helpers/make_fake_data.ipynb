{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f9a745-2335-4485-8eb7-49b7f3b9c2af",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ee141cf-15ba-43f0-a064-680f2f54125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c9f68-a4e4-43c8-aa93-6404e5ae6a6a",
   "metadata": {},
   "source": [
    "# open original vcf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e68ebf31-994b-41df-a255-ed7664e22c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/minhtoo.lin/repos/nf-gwas/tests/input/pipeline/example.vcf\", \"r\") as f:\n",
    "    vcf_orig = f.readlines()\n",
    "\n",
    "header_lines_orig = vcf_orig[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8595ceee-07bb-4c62-b921-bc819ea8e07f",
   "metadata": {},
   "source": [
    "# prepare new chromosome header line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae58c404-2206-4d2f-8672-cd72aa52bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just copy the fixed part\n",
    "chrom_header_line_base = \"#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\"\n",
    "\n",
    "num_individuals = 50_000\n",
    "chrom_header_line_chars = [chrom_header_line_base]\n",
    "for i in range(1, num_individuals + 1):  # 1-indexed\n",
    "    chrom_header_line_chars.append(f\"\\t{i}\")\n",
    "chrom_header_line_chars.append(\"\\n\")\n",
    "\n",
    "chrom_header_line_new = \"\".join(chrom_header_line_chars)\n",
    "\n",
    "with open(\"../data/example_big.vcf\", \"w\") as f:\n",
    "    # write 6 header lines\n",
    "    f.writelines(header_lines_orig)\n",
    "    # write new chromosome header line\n",
    "    f.write(chrom_header_line_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e32a414-947f-4fd3-a1a0-6f543e387b34",
   "metadata": {},
   "source": [
    "# prepare new data lines, row by row - use random.choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f2d9852-3259-4684-a365-43fddd918b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_CHOICES = [\"0/0\", \"0/1\", \"1/1\"]\n",
    "num_positions = 1_000\n",
    "\n",
    "# append\n",
    "with open(\"../data/example_big.vcf\", \"a\") as f:\n",
    "    for row_idx in range(1, num_positions + 1):  # 1-indexed, up to num_position rows\n",
    "        line_base = f\"1\\t{row_idx}\\t{row_idx}\\t2\\t1\\t.\\t.\\tPR\\tGT\"\n",
    "        curr_line_chars = [line_base]\n",
    "        \n",
    "        for i in range(num_individuals):\n",
    "            random_genotype = random.choice(GT_CHOICES)\n",
    "            curr_line_chars.append(f\"\\t{random_genotype}\")\n",
    "        curr_line_chars.append(\"\\n\")\n",
    "            \n",
    "        f.write(\"\".join(curr_line_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f81030-aecf-42e5-a819-787f64c7337f",
   "metadata": {},
   "source": [
    "# write fake phenotypes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "112c7c42-fdd5-41fe-ac61-a95be412a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_phenotypes_total = 10\n",
    "num_phenotypes_per_file = 1\n",
    "\n",
    "assert num_phenotypes_total % num_phenotypes_per_file == 0\n",
    "\n",
    "header_base = \"FID IID\"\n",
    "curr_pheno_idx = 1  # 1-indexed\n",
    "for file_idx in range(num_phenotypes_total // num_phenotypes_per_file):\n",
    "    with open(f\"../data/phenotype_big_{file_idx}.txt\", \"w\") as f:\n",
    "        # write header\n",
    "        header_chars = [header_base]\n",
    "        for pheno_idx in range(curr_pheno_idx, curr_pheno_idx + num_phenotypes_per_file):\n",
    "            header_chars.append(f\" Y{pheno_idx}\")\n",
    "        header_chars.append(\"\\n\")\n",
    "        f.write(\"\".join(header_chars))\n",
    "\n",
    "        # draw from normal distribution\n",
    "        random_nums = np.random.normal(size=(num_individuals, num_phenotypes_per_file))\n",
    "\n",
    "        # write data rows\n",
    "        for row_idx in range(1, num_individuals + 1): # 1-indexed\n",
    "            row_chars = [f\"{row_idx} {row_idx}\"]\n",
    "            for pheno_idx in range(num_phenotypes_per_file):\n",
    "                row_chars.append(f\" {random_nums[row_idx - 1][pheno_idx]}\")  # 0-indexed\n",
    "            row_chars.append(\"\\n\")\n",
    "            f.write(\"\".join(row_chars))\n",
    "\n",
    "    curr_pheno_idx += num_phenotypes_per_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e37b47-5c97-4501-9c14-8cfaa781b7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
