{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f9a745-2335-4485-8eb7-49b7f3b9c2af",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee141cf-15ba-43f0-a064-680f2f54125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c9f68-a4e4-43c8-aa93-6404e5ae6a6a",
   "metadata": {},
   "source": [
    "# open original vcf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e68ebf31-994b-41df-a255-ed7664e22c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/minhtoo.lin/repos/nf-gwas/tests/input/pipeline/example.vcf\", \"r\") as f:\n",
    "    vcf_orig = f.readlines()\n",
    "\n",
    "header_lines_orig = vcf_orig[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f7a1c-f2b8-4abb-a52b-e9b7a4a25ee4",
   "metadata": {},
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cfd5433-37f5-4e09-ac82-1aa1b8982142",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_positions = 1_000_000\n",
    "num_individuals = 50_000\n",
    "# prev VCF (16 GB) was 100k positions x 100k individuals\n",
    "# new VC (200 GB) is 1 million position x 50k individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8595ceee-07bb-4c62-b921-bc819ea8e07f",
   "metadata": {},
   "source": [
    "# prepare new chromosome header line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae58c404-2206-4d2f-8672-cd72aa52bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just copy the fixed part\n",
    "chrom_header_line_base = \"#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\"\n",
    "\n",
    "chrom_header_line_chars = [chrom_header_line_base]\n",
    "for i in range(1, num_individuals + 1):  # 1-indexed\n",
    "    chrom_header_line_chars.append(f\"\\t{i}\")\n",
    "chrom_header_line_chars.append(\"\\n\")\n",
    "\n",
    "chrom_header_line_new = \"\".join(chrom_header_line_chars)\n",
    "\n",
    "with open(\"../data/example_bigger.vcf\", \"w\") as f:\n",
    "    # write 6 header lines\n",
    "    f.writelines(header_lines_orig)\n",
    "    # write new chromosome header line\n",
    "    f.write(chrom_header_line_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e32a414-947f-4fd3-a1a0-6f543e387b34",
   "metadata": {},
   "source": [
    "# prepare new data lines, row by row - use random.choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f2d9852-3259-4684-a365-43fddd918b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1000000/1000000 [3:15:43<00:00, 85.16it/s]\n"
     ]
    }
   ],
   "source": [
    "GT_CHOICES = np.array([\"0/0\", \"0/1\", \"1/1\"])\n",
    "\n",
    "# append\n",
    "with open(\"../data/example_bigger.vcf\", \"a\") as f:\n",
    "    for row_idx in tqdm(range(1, num_positions + 1)):  # 1-indexed, up to num_position rows\n",
    "        line_base = f\"1\\t{row_idx}\\t{row_idx}\\t2\\t1\\t.\\t.\\tPR\\tGT\"\n",
    "        curr_line_chars = [line_base]\n",
    "        \n",
    "        randints = np.random.randint(0, len(GT_CHOICES), size=(num_individuals))\n",
    "        curr_line_chars.append(\"\\t\")\n",
    "        curr_line_chars.append(\"\\t\".join(GT_CHOICES[randints]))\n",
    "        curr_line_chars.append(\"\\n\")\n",
    "\n",
    "        f.write(\"\".join(curr_line_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f81030-aecf-42e5-a819-787f64c7337f",
   "metadata": {},
   "source": [
    "# write fake phenotypes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "112c7c42-fdd5-41fe-ac61-a95be412a056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:00<00:00, 71659.92it/s]\n"
     ]
    }
   ],
   "source": [
    "num_phenotypes_total = 20\n",
    "num_phenotypes_per_file = 20\n",
    "\n",
    "assert num_phenotypes_total % num_phenotypes_per_file == 0\n",
    "\n",
    "header_base = \"FID IID\"\n",
    "curr_pheno_idx = 1  # 1-indexed\n",
    "for file_idx in range(num_phenotypes_total // num_phenotypes_per_file):\n",
    "    with open(f\"../data/phenotype_biggest_20_{file_idx}.txt\", \"w\") as f:\n",
    "        # write header\n",
    "        header_chars = [header_base]\n",
    "        for pheno_idx in range(curr_pheno_idx, curr_pheno_idx + num_phenotypes_per_file):\n",
    "            header_chars.append(f\" Y{pheno_idx}\")\n",
    "        header_chars.append(\"\\n\")\n",
    "        f.write(\"\".join(header_chars))\n",
    "\n",
    "        # draw from normal distribution\n",
    "        random_nums = np.random.normal(size=(num_individuals, num_phenotypes_per_file))\n",
    "\n",
    "        # write data rows\n",
    "        for row_idx in tqdm(range(1, num_individuals + 1)): # 1-indexed\n",
    "            row_chars = [f\"{row_idx} {row_idx}\"]\n",
    "            for pheno_idx in range(num_phenotypes_per_file):\n",
    "                row_chars.append(f\" {random_nums[row_idx - 1][pheno_idx]}\")  # 0-indexed\n",
    "            row_chars.append(\"\\n\")\n",
    "            f.write(\"\".join(row_chars))\n",
    "\n",
    "    curr_pheno_idx += num_phenotypes_per_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422b63e-f1f1-48a9-b216-7d34e9a493cc",
   "metadata": {},
   "source": [
    "# write rsids.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2392ed-91ba-4e50-a6dd-788f70533d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1000000/1000000 [00:00<00:00, 2727910.34it/s]\n"
     ]
    }
   ],
   "source": [
    "rsid_init = 270000\n",
    "header_line = \"CHROM\tPOS\tRSID\tREF\tALT\tAAF\\n\"\n",
    "with open(\"../data/rsids_big.tsv\", \"w\") as f:\n",
    "    f.write(header_line)\n",
    "\n",
    "    for row_idx in tqdm(range(1, num_positions + 1)):\n",
    "        f.write(f\"1\\t{row_idx}\\trs{rsid_init + row_idx}\\t2\\t1\\t0,1\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e37b47-5c97-4501-9c14-8cfaa781b7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e917488-50fc-4124-ac31-db6b0727a5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
